import os
from functools import partial
from dotenv import load_dotenv
import dspy
from tidb_vector.integrations import TiDBVectorClient
from utils import sentence_transformer_embedding_function, TidbRM, RAG

# Load the environment variables from the .env file.
load_dotenv()

# The configuration for the sentence-transformers model.
transformer = {
    # The name or path of the sentence-transformers model to use.
    "model": "sentence-transformers/multi-qa-mpnet-base-dot-v1",
    # The dimension of the vector generated by the embedding model.
    "embed_model_dims": 768,
}

embedding_function = partial(sentence_transformer_embedding_function, transformer["model"])

# The configuration for the TiDBVectorClient.
tidb_vector_client = TiDBVectorClient(
    # The table which will store the TiDB vector data.
    table_name=os.environ.get('TIDB_TABLE_NAME', 'embedded_documents'),
    # The connection string to the TiDB cluster.
    # The connection string should be in the format of:
    # mysql+pymysql://<USER>:<PASSWORD>@<HOST>:4000/<DATABASE>?ssl_ca=<CA_PATH>&ssl_verify_cert=true&ssl_verify_identity=true
    connection_string=os.environ.get('TIDB_DATABASE_URL'),
    # The dimension of the vector generated by the embedding model.
    vector_dimension=transformer["embed_model_dims"],
    # Determine whether to recreate the table if it already exists.
    drop_existing_table=True,
)

print("Connected to TiDB.")
print("describe table:", tidb_vector_client.execute("describe embedded_documents;"))

print("Initializing the TidbRM model...")
retriever_model = TidbRM(tidb_vector_client=tidb_vector_client, embedding_function=embedding_function)
print("TidbRM model initialized successfully.")

print("Loading sample data...")
# test sample data
# load sample_data.txt  if not local file, you can use requests.get(url).text
# sample data url: https://raw.githubusercontent.com/wxywb/dspy_dataset_sample/master/sample_data.txt
with open('sample_data.txt', 'r') as f:
    # I prepare a small set of data for speeding up embedding, you can replace it with your own data.
    print("sample_data.txt found.")
    sample_data = f.read()
print("Sample data loaded successfully.")

print("Embedding sample data...")
documents = []
for idx, passage in enumerate(sample_data.split('\n')):
    embedding = embedding_function([passage])[0]
    print(idx, passage[:10], embedding[:5])
    if len(passage) == 0:
        continue
    documents.append({
        "id": str(idx),
        "text": passage,
        "embedding": embedding,
        "metadata": {"category": "album"},
    })
print("Sample data embedded successfully.")
print("Sample data number:", len(documents))

print("Inserting documents into TiDB...")
tidb_vector_client.insert(
    ids=[doc["id"] for doc in documents],
    texts=[doc["text"] for doc in documents],
    embeddings=[doc["embedding"] for doc in documents],
    metadatas=[doc["metadata"] for doc in documents],
)
print("Documents inserted successfully.")

language_model = dspy.OllamaLocal(
    model=os.environ.get('LM_MODEL_NAME', 'llama3:8b'),
    base_url=os.environ.get('OLLAMA_BASE_URL'),
    api_key=os.environ.get('OLLAMA_API_KEY')
)
dspy.settings.configure(lm=language_model)

rag = RAG(retriever_model)


if __name__ == '__main__':
    print("Answering the question: 'who write At My Window'...")
    print(rag("who write At My Window").answer)
    print(language_model.inspect_history(n=1))
