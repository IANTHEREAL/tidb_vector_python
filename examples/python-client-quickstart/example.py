import os

from tidb_vector.integrations import TiDBVectorClient
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

# Step 1. Initialize embedding model

print("Downloading and loading the embedding model...")
embed_model = SentenceTransformer("sentence-transformers/msmarco-MiniLM-L12-cos-v5", trust_remote_code=True)
embed_model_dims = embed_model.get_sentence_embedding_dimension()


def text_to_embedding(text):
    """Generates vector embeddings for the given text."""
    embedding = embed_model.encode(text)
    return embedding.tolist()


# Step 2. Initialize TiDBVectorClient instance

load_dotenv()

vector_store = TiDBVectorClient(
    # The table which will store the vector data.
    table_name='embedded_documents',
    # The connection string to the TiDB cluster.
    # The connection string should be in the format of:
    # mysql+pymysql://<USER>:<PASSWORD>@<HOST>:4000/<DATABASE>?ssl_ca=<CA_PATH>&ssl_verify_cert=true&ssl_verify_identity=true
    connection_string=os.environ.get('TIDB_DATABASE_URL'),
    # The dimension of the vector generated by the embedding model.
    vector_dimension=embed_model_dims,
    # Determine whether to recreate the table if it already exists.
    drop_existing_table=True,
)

# Step 3. Bulk insert objects and their embeddings

documents = [
    {
        "id": "f8e7dee2-63b6-42f1-8b60-2d46710c1971",
        "text": "dog",
        "embedding": text_to_embedding("dog"),
        "metadata": {"category": "animal"},
    },
    {
        "id": "8dde1fbc-2522-4ca2-aedf-5dcb2966d1c6",
        "text": "fish",
        "embedding": text_to_embedding("fish"),
        "metadata": {"category": "animal"},
    },
    {
        "id": "e4991349-d00b-485c-a481-f61695f2b5ae",
        "text": "tree",
        "embedding": text_to_embedding("tree"),
        "metadata": {"category": "plant"},
    },
]

vector_store.insert(
    ids=[doc["id"] for doc in documents],
    texts=[doc["text"] for doc in documents],
    embeddings=[doc["embedding"] for doc in documents],
    metadatas=[doc["metadata"] for doc in documents],
)

# Step 4. Perform vector search to find the most semantically similar documents to the query.


def print_result(query, result):
    print(f"Search result (\"{query}\"):")
    for r in result:
        print(f"- text: \"{r.document}\", distance: {r.distance}")


query = "a swimming animal"
query_embedding = text_to_embedding(query)
search_result = vector_store.query(query_embedding, k=3)
print_result(query, search_result)
